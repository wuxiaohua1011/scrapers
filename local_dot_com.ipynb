{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: Unidecode in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (1.3.8)\n",
      "Requirement already satisfied: bs4 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/michaelwu/opt/anaconda3/envs/yelp_crawler/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "# Imports for data management\n",
    "!pip install pandas Unidecode bs4\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Import for crawling and scraping\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "from urllib.parse import urlparse, unquote\n",
    "from typing import List \n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word: str = \"Security Camera Installation\"\n",
    "loc:str = \"Washington\"\n",
    "offset: int = 0\n",
    "i = offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section is used to parse a business page\n",
    "\n",
    "# TODO(Novena): Add the code to parse the business search page\n",
    "def get_biz_urls(key_word, loc, page_num=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Getting results from yelp\n",
    "    The output is a list of business urls\n",
    "    \"\"\"\n",
    "    url = f\"https://www.local.com/business/results/listing.cfm?s={key_word}&ar={loc}&wpn={page_num}\"\n",
    "    print(f\"Iteration [{i}] - Searching for [{key_word} in [{loc}] with offset [{i}]. URL: [{url}]\")\n",
    "\n",
    "    page = requests.get(url)\n",
    "    # TODO: novena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biz_info(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Getting the business information from the business page\n",
    "    \"\"\"\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_pages(key_word, loc, num_entries) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Getting multiple pages of business information\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word: str = \"CCTV\"\n",
    "loc:str = \"Salt+Lake+City%2C+UT\"\n",
    "num_results = 10\n",
    "df = get_multi_pages(key_word, loc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path:Path = Path('./data/local_dot_com.csv')\n",
    "if output_file_path.parent.exists() == False:\n",
    "    output_file_path.parent.mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "df.to_csv(output_file_path.as_posix(), index=False)\n",
    "print(f\"[{len(df)}] Data saved to {output_file_path.as_posix()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
